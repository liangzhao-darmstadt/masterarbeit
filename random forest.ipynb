{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0 - import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyreadr as py\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os_windows: True\n",
      "os_ubuntu: False\n",
      "sys.version: 3.7.1 (default, Oct 28 2018, 08:39:03) [MSC v.1912 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import sys\n",
    "\n",
    "os_windows = False\n",
    "os_ubuntu = False\n",
    "if platform.platform() == \"Linux-5.4.0-58-generic-x86_64-with-glibc2.10\":\n",
    "    os_ubuntu = True\n",
    "else:\n",
    "    os_windows = True\n",
    "print(\"os_windows: \" + str(os_windows))\n",
    "print(\"os_ubuntu: \" + str(os_ubuntu))\n",
    "\n",
    "print(\"sys.version: \" + str(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.2\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "print(sklearn.__version__)\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - define helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization_data(data, eta=2):\n",
    "    data_normalized = np.copy(data)\n",
    "    shape0 = data.shape[0]\n",
    "    shape1 = data.shape[1]\n",
    "    mean = np.mean(data, axis=0)\n",
    "    std = np.std(data, axis=0)\n",
    "    for i in range(shape1):\n",
    "        for j in range(shape0):\n",
    "            data_normalized[j, i] = (data[j, i] - mean[i]) / (std[i] * eta)\n",
    "    return data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix the fault free data and faulty data\n",
    "def mix_shuffle_data(fault_free_data, faulty_data):\n",
    "\n",
    "    fault_free_label = np.zeros((fault_free_data.shape[0], 1))\n",
    "    faulty_label = np.ones((faulty_data.shape[0], 1))\n",
    "\n",
    "    a1 = np.hstack((fault_free_label, fault_free_data))\n",
    "    a2 = np.hstack((faulty_label, faulty_data))\n",
    "    mixed_data = np.vstack((a1, a2))\n",
    "    np.random.shuffle(mixed_data)\n",
    "    return mixed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_error_RF(prediction, label):\n",
    "    detection_rate=prediction.sum()/prediction.shape[0]\n",
    "    s1=label+str(detection_rate)\n",
    "    \n",
    "    print(s1)\n",
    "    return detection_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os_windows:\n",
    "    root_folder = \"C:/Users/liang/Masterarbeit_Jupyter_Lab/\"\n",
    "else:\n",
    "    root_folder = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eta: 2\n"
     ]
    }
   ],
   "source": [
    "eta = 2\n",
    "print(\"eta: \" + str(eta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data, normalize_data = True, True\n",
    "\n",
    "# fault_free_train_samplesizeX: X data from TEP_FaultFree_Training.RData\n",
    "if read_data and normalize_data:\n",
    "    fault_free_train_samplesize20000 = pd.read_csv(\n",
    "        root_folder + \"data_set_csv/fault_free_train_sample_size=20000\", sep=\",\", header=None,\n",
    "    ).to_numpy()\n",
    "    fault_free_train_samplesize40000 = pd.read_csv(\n",
    "        root_folder + \"data_set_csv/fault_free_train_sample_size=40000\", sep=\",\", header=None,\n",
    "    ).to_numpy()\n",
    "    fault_free_train_samplesize100000 = pd.read_csv(\n",
    "        root_folder + \"data_set_csv/fault_free_train_sample_size=100000\", sep=\",\", header=None,\n",
    "    ).to_numpy()\n",
    "    fault_free_train_samplesize250000 = pd.read_csv(\n",
    "        root_folder + \"data_set_csv/fault_free_train_sample_size=250000\", sep=\",\", header=None,\n",
    "    ).to_numpy()\n",
    "\n",
    "    fault_free_train_samplesize20000_normalized = normalization_data(fault_free_train_samplesize20000, eta)\n",
    "    fault_free_train_samplesize40000_normalized = normalization_data(fault_free_train_samplesize40000, eta)\n",
    "    fault_free_train_samplesize100000_normalized = normalization_data(fault_free_train_samplesize100000, eta)\n",
    "    fault_free_train_samplesize250000_normalized = normalization_data(fault_free_train_samplesize250000, eta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 52)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fault_free_test1: first 20000 data from TEP_FaultFree_Testing.RData\n",
    "fault_free_test1 = pd.read_csv(root_folder + \"data_set_csv/fault_free_test1=20000\", sep=\",\", header=None).to_numpy()\n",
    "fault_free_test1_normalized = normalization_data(fault_free_test1, eta)\n",
    "fault_free_test1_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 52)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fault_free_test2: second 20000 data from TEP_FaultFree_Testing.RData\n",
    "fault_free_test2 = pd.read_csv(root_folder + \"data_set_csv/fault_free_test2=20000\", sep=\",\", header=None).to_numpy()\n",
    "fault_free_test2_normalized = normalization_data(fault_free_test2, eta)\n",
    "fault_free_test2_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(470400, 52)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faulty_train: 10% data (470400) from TEP_Faulty_Training.RData\n",
    "faulty_train = pd.read_csv(root_folder + \"data_set_csv/faulty_train=10%\", sep=\",\", header=None).to_numpy()\n",
    "faulty_train_normalized = normalization_data(faulty_train, eta)\n",
    "faulty_train_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784000, 52)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# faulty_test: 10% data (784000) from TEP_Faulty_Testing.RData\n",
    "faulty_test = pd.read_csv(root_folder + \"data_set_csv/faulty_test=10%\", sep=\",\", header=None).to_numpy()\n",
    "faulty_test_normalized = normalization_data(faulty_test, eta)\n",
    "faulty_test_normalized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(650000, 53)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fault_free_train = fault_free_train_samplesize250000\n",
    "fault_free_train_normalized = fault_free_train_samplesize250000_normalized\n",
    "faulty_train_sample_size = 400000\n",
    "\n",
    "train_data = mix_shuffle_data(fault_free_train, faulty_train[:faulty_train_sample_size, :])\n",
    "train_data_normalized = mix_shuffle_data(\n",
    "    fault_free_train_normalized, faulty_train_normalized[:faulty_train_sample_size, :]\n",
    ")\n",
    "\n",
    "train_data.shape\n",
    "train_data_normalized.shape\n",
    "# np.random.shuffle(train_data)\n",
    "# np.random.shuffle(train_data_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - set model parameters using grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# model = RandomForestClassifier()\n",
    "# evaluate the model\n",
    "# cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "sample_size_start = 0\n",
    "sample_size_end = 5000\n",
    "\n",
    "# if use the normalized data: normalization improve performance\n",
    "set_normalized = True\n",
    "set_grid_search = True\n",
    "\n",
    "if set_normalized:\n",
    "    X = train_data_normalized[sample_size_start:sample_size_end, 1:]\n",
    "    y = train_data_normalized[sample_size_start:sample_size_end, 0]\n",
    "else:\n",
    "    X = train_data[sample_size_start:sample_size_end, 1:]\n",
    "    y = train_data[sample_size_start:sample_size_end, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.00419509, -0.10971104, ..., -0.70422291,\n",
       "        -0.07203067, -0.35302938],\n",
       "       [ 0.        ,  0.22750791, -0.6937791 , ...,  0.17309119,\n",
       "        -0.6335835 , -0.20452161],\n",
       "       [ 1.        , -0.07479211, -0.32015851, ...,  0.30704842,\n",
       "         0.00597616, -0.14314217],\n",
       "       ...,\n",
       "       [ 1.        ,  1.94557093, -0.4168506 , ...,  0.29437501,\n",
       "        -0.08823172,  0.15740965],\n",
       "       [ 0.        , -0.39390043, -0.042429  , ..., -0.12121977,\n",
       "         0.41020926,  0.89442484],\n",
       "       [ 0.        ,  0.56744434, -0.09389007, ...,  0.54360275,\n",
       "         0.14764315,  0.42198376]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.19509221e-03, -1.09711039e-01,  7.29694046e-01, ...,\n",
       "        -7.04222915e-01, -7.20306737e-02, -3.53029377e-01],\n",
       "       [ 2.27507905e-01, -6.93779098e-01,  6.06652999e-01, ...,\n",
       "         1.73091193e-01, -6.33583496e-01, -2.04521610e-01],\n",
       "       [-7.47921134e-02, -3.20158514e-01, -7.06274079e-02, ...,\n",
       "         3.07048421e-01,  5.97616421e-03, -1.43142173e-01],\n",
       "       ...,\n",
       "       [ 3.34557921e-01, -1.35058922e-01, -1.93774977e-02, ...,\n",
       "        -4.59889051e-01, -8.27734497e-01,  2.16336961e-01],\n",
       "       [ 1.20035124e+00, -1.08593230e-01, -1.02253225e-01, ...,\n",
       "        -5.94988644e-01,  1.05922832e+00,  7.26696299e-01],\n",
       "       [-6.34157104e-01,  8.16257849e-01, -2.54833171e-02, ...,\n",
       "         1.37368551e+00, -6.97700413e-04,  5.95362245e-02]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:    3.9s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:   18.3s\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:   27.8s\n",
      "[Parallel(n_jobs=-1)]: Done  35 out of  45 | elapsed:   39.5s remaining:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done  40 out of  45 | elapsed:   46.7s remaining:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best estimator is {'max_depth': 30, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "if set_grid_search:\n",
    "    # model fitting and hyperparameter tunning using gridsearch\n",
    "    test_RF_classifier = RandomForestClassifier()\n",
    "    # weights = np.linspace(0.05, 0.95, 20)\n",
    "    prams = {\n",
    "        \"n_estimators\": [100, 200, 500],\n",
    "        \"max_depth\": [15, 20, 25, 30, 35], \n",
    "    }\n",
    "    model = GridSearchCV(test_RF_classifier, param_grid=prams, verbose=10, n_jobs=-1, scoring=\"accuracy\", cv=3)\n",
    "    model.fit(X, y)\n",
    "    print(\"Best estimator is\", model.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=30, n_estimators=500, n_jobs=-1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth=model.best_params_.get('max_depth')\n",
    "n_estimators=model.best_params_.get('n_estimators')\n",
    "\n",
    "RF_classifier = RandomForestClassifier(n_jobs=-1, max_depth=max_depth, n_estimators=n_estimators)\n",
    "RF_classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fault_free_train_samplesize250000_normalized_pred: 0.000948\n",
      "fault_free_test1_normalized_pred: 0.00055\n",
      "fault_free_test2_normalized_pred: 0.0008\n",
      "faulty_train_normalized_pred: 0.993218537414966\n",
      "faulty_test_normalized_pred: 0.9968686224489796\n"
     ]
    }
   ],
   "source": [
    "if set_normalized:\n",
    "    fault_free_train_samplesize250000_normalized_pred = RF_classifier.predict(fault_free_train_samplesize250000_normalized)\n",
    "    fault_free_test1_normalized_pred = RF_classifier.predict(fault_free_test1_normalized)\n",
    "    fault_free_test2_normalized_pred = RF_classifier.predict(fault_free_test2_normalized)\n",
    "    faulty_train_normalized_pred = RF_classifier.predict(faulty_train_normalized)\n",
    "    faulty_test_normalized_pred = RF_classifier.predict(faulty_test_normalized)\n",
    "    pred_error_RF(fault_free_train_samplesize250000_normalized_pred, \"fault_free_train_samplesize250000_normalized_pred: \")\n",
    "    pred_error_RF(fault_free_test1_normalized_pred, \"fault_free_test1_normalized_pred: \")\n",
    "    pred_error_RF(fault_free_test2_normalized_pred, \"fault_free_test2_normalized_pred: \")\n",
    "    pred_error_RF(faulty_train_normalized_pred, \"faulty_train_normalized_pred: \")\n",
    "    pred_error_RF(faulty_test_normalized_pred, \"faulty_test_normalized_pred: \")\n",
    "else:\n",
    "    fault_free_train_samplesize250000_pred = RF_classifier.predict(fault_free_train_samplesize250000)\n",
    "    fault_free_test1_pred = RF_classifier.predict(fault_free_test1)\n",
    "    fault_free_test2_pred = RF_classifier.predict(fault_free_test2)\n",
    "    faulty_train_pred = RF_classifier.predict(faulty_train)\n",
    "    faulty_test_pred = RF_classifier.predict(faulty_test)\n",
    "    pred_error_RF(fault_free_train_samplesize250000_pred, \"fault_free_train_samplesize250000: \")\n",
    "    pred_error_RF(fault_free_test1_pred, \"fault_free_test1: \")\n",
    "    pred_error_RF(fault_free_test2_pred, \"fault_free_test2: \")\n",
    "    pred_error_RF(faulty_train_pred, \"faulty_train: \")\n",
    "    pred_error_RF(faulty_test_pred, \"faulty_test: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "output_auto_scroll": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
